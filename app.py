import streamlit as st
from dandelion import DataTXT
from textblob import TextBlob
import json

st.set_page_config(page_title="SEO Entity & Sentiment Analyzer", layout="wide")
st.title("ğŸ” SEO Entity & Sentiment Analyzer (Dandelion + TextBlob)")

# Input fields
api_token = st.text_input("ğŸ”‘ Enter your Dandelion API Token", type="password")
user_text = st.text_area("âœï¸ Enter Your Content", height=200)
ref_text = st.text_area("ğŸ“„ (Optional) Enter Competitor Content", height=200)
analyze_btn = st.button("ğŸš€ Analyze")

# Industry-specific entity suggestions (simplified and extendable)
industry_keywords = {
    "photography": [
        "Ghost Mannequin Photography", "Flat Lay Product Photography", "Editorial Photography",
        "Retouching", "Casting", "Studio Consulting"
    ],
    "web3": ["Blockchain", "DAO", "Smart Contract", "Tokenomics", "DeFi", "NFT"]
}

def suggest_entities(user_entities, text):
    suggested = []
    for industry, terms in industry_keywords.items():
        for term in terms:
            if term.lower() not in [e.lower() for e in user_entities] and term.lower() in text.lower():
                suggested.append(term)
    return suggested

if api_token and user_text.strip() and analyze_btn:
    datatxt = DataTXT(token=api_token, min_confidence=0.6)

    # Entity extraction
    st.header("ğŸ§  Entity Extraction")
    try:
        nex_result = datatxt.nex(user_text, include="types,uri")
        seen = set()
        entity_data = []
        for ann in nex_result.annotations:
            label = ann.label.strip()
            if label.lower() not in seen:
                seen.add(label.lower())
                entity_data.append({
                    "label": label,
                    "type": ann.types[0].split("/")[-1] if ann.types else "Thing",
                    "uri": ann.uri if hasattr(ann, "uri") and ann.uri else None
                })

        if entity_data:
            st.success(f"âœ… Found {len(entity_data)} Unique Entities:")
            for ent in entity_data:
                if ent["uri"]:
                    st.markdown(f"- **[{ent['label']}]({ent['uri']})** ({ent['type']})")
                else:
                    st.markdown(f"- **{ent['label']}** ({ent['type']})")
        else:
            st.warning("No entities found.")
    except Exception as e:
        st.error(f"Entity extraction error: {e}")
        entity_data = []

    # Suggest additional entities
    st.header("ğŸ§© Suggested Industry Entities")
    suggestions = suggest_entities([e["label"] for e in entity_data], user_text)
    if suggestions:
        for term in suggestions:
            st.markdown(f"- ğŸ“Œ {term}")
    else:
        st.info("No additional relevant entities found.")

    # Sentiment analysis
    st.header("ğŸ’¬ Sentiment Analysis")
    try:
        blob = TextBlob(user_text)
        polarity = blob.sentiment.polarity
        sentiment_label = "Positive ğŸ˜Š" if polarity > 0 else "Negative ğŸ˜ " if polarity < 0 else "Neutral ğŸ˜"
        st.markdown(f"**Sentiment Score:** `{polarity:.3f}`")
        st.markdown(f"**Interpretation:** {sentiment_label}")
    except Exception as e:
        st.error(f"Sentiment analysis error: {e}")

    # Competitor comparison
    if ref_text.strip():
        st.header("ğŸ“ Competitor Comparison")
        try:
            comp_result = datatxt.nex(ref_text, include="types,uri")
            user_labels = set([e["label"].lower() for e in entity_data])
            comp_entities = [{
                "label": ann.label,
                "type": ann.types[0].split("/")[-1] if ann.types else "Thing",
                "uri": ann.uri if hasattr(ann, "uri") and ann.uri else None
            } for ann in comp_result.annotations]
            comp_labels = set([e["label"].lower() for e in comp_entities])

            missing = comp_labels - user_labels
            extra = user_labels - comp_labels
            common = user_labels & comp_labels
            coverage_score = len(common) / len(comp_labels.union(user_labels)) if comp_labels.union(user_labels) else 0

            st.markdown(f"**Coverage Depth Score:** `{coverage_score:.2%}`")
            st.progress(coverage_score)

            if missing:
                st.warning("ğŸ“Œ Missing Entities:")
                for ent in comp_entities:
                    if ent["label"].lower() in missing:
                        st.markdown(f"- â— {ent['label']}")
            if extra:
                st.info("ğŸŒ¿ Extra Entities in Your Content:")
                for ent in entity_data:
                    if ent["label"].lower() in extra:
                        st.markdown(f"- âœ… {ent['label']}")
            if common:
                st.success("ğŸ¯ Shared Entities:")
                for label in sorted(common):
                    st.markdown(f"- ğŸ” {label}")
        except Exception as e:
            st.error(f"Competitor analysis error: {e}")

    # JSON-LD Entity Schema Markup
    if entity_data:
        st.header("ğŸ§¾ Entity Schema Markup Generator")
        biz_name = st.text_input("ğŸ·ï¸ Business Name")
        biz_desc = st.text_area("ğŸ“ Business Description")
        biz_url = st.text_input("ğŸ”— Website URL")
        biz_logo = st.text_input("ğŸ–¼ï¸ Logo URL")
        biz_image = st.text_input("ğŸ“· Image URL")
        biz_keywords = st.text_area("ğŸ”‘ Keywords (comma-separated)")

        if biz_name and biz_desc and biz_url:
            schema = {
                "@context": "https://schema.org",
                "@type": "LocalBusiness",
                "name": biz_name,
                "description": biz_desc,
                "url": biz_url,
                "logo": biz_logo if biz_logo else None,
                "image": [biz_image] if biz_image else None,
                "keywords": [k.strip() for k in biz_keywords.split(",")] if biz_keywords else [],
                "mainEntity": [
                    {
                        "@type": ent["type"],
                        "name": ent["label"],
                        **({"sameAs": ent["uri"]} if ent["uri"] else {})
                    }
                    for ent in entity_data
                ]
            }
            # Clean empty fields
            schema = {k: v for k, v in schema.items() if v}
            schema_str = json.dumps(schema, indent=2)
            st.code(schema_str, language="json")
            st.download_button("â¬‡ï¸ Download Schema", schema_str, file_name="entity_schema.json", mime="application/json")
        else:
            st.info("â„¹ï¸ Fill in business name, description, and URL to generate schema.")
else:
    st.info("ğŸ” Enter your API key and content, then click Analyze.")
